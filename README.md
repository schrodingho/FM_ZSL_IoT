# Leveraging Foundation Models for Zero-Shot IoT Sensing

[//]: # ([![]&#40;https://img.shields.io/badge/ECAI-2024-green?style=flat&#41;]&#40;https://www.ecai2024.eu/programme/accepted-papers#:~:text=and%20Odile%20Papini-,M939,-Leveraging%20Foundation%20Models&#41; )
[![](https://img.shields.io/badge/arXiv:2407.19893-red?style=flat)](https://arxiv.org/pdf/2407.19893)
## Abstract
Deep learning models are increasingly deployed on edge Internet of Things (IoT) devices. However, these models typically operate under supervised conditions and fail to recognize unseen classes different from training. To address this, zero-shot learning (ZSL) aims to classify data of unseen classes with the help of semantic information. Foundation models (FMs) trained on web-scale data have shown impressive ZSL capability in natural language processing and visual understanding. However, leveraging FMs' generalized knowledge for zero-shot IoT sensing using signals such as mmWave, IMU, and Wi-Fi has not been fully investigated. In this work, we align the IoT data embeddings with the semantic embeddings generated by an FM's text encoder for zero-shot IoT sensing. To utilize the physics principles governing the generation of IoT sensor signals to derive more effective prompts for semantic embedding extraction, we propose to use cross-attention to combine a learnable soft prompt that is optimized automatically on training data and an auxiliary hard prompt that encodes domain knowledge of the IoT sensing task. To address the problem of IoT embeddings biasing to seen classes due to the lack of unseen class data during training, we propose using data augmentation to synthesize unseen class IoT data for fine-tuning the IoT feature extractor and embedding projector. We evaluate our approach on multiple IoT sensing tasks. Results show that our approach achieves superior open-set detection and generalized zero-shot learning performance compared with various baselines.
## Environment Setup

## Usage
1. Easy Running
```bash
python main.py
```
    